
//
//  ManifezzClass: KrawlMaster 
//  UtilityTest
//
//  Created by william donner on 4/19/19.
//

import Foundation
import Kanna

func cleanOuputs(outpath:String) {
    do {
        // clear the output directory
        let fm = FileManager.default
        let dir = URL(fileURLWithPath:outpath)
        var counter = 0
        let furls = try fm.contentsOfDirectory(at: dir, includingPropertiesForKeys: nil)
        for furl in furls {
            try fm.removeItem(at: furl)
            counter += 1
        }
        print("[crawler] Cleaned \(counter) files from ", outpath )
    }
    catch {print("[crawler] Could not clean outputs \(error)")}
}

func checkForBonusTags(name:String?)->String? {
    
    if let songName = name {
        let shorter = songName.trimmingCharacters(in: .whitespacesAndNewlines).lowercased()
        for tuneTag in crawlerKeyTags {
            // print("Checking \(String(describing: shorter)) -- \(tuneTag)")
            if shorter.hasPrefix(tuneTag) {
                //print("Checked \(String(describing: name)) ok")
                return tuneTag
            }
        }
    }
    // print("Checked \(String(describing: name)) fail")
    return nil
}
/// add new code to write md files for Publish ing static site


func createMarkDown(_ aurl: String,name:String?,links:[(String,String)] ) {
    
    func createMdFile(_ s:String,tags:[String]=[]) {
        var moretags:Set<String>=[]
        for link in links {
            if  let bonustag = checkForBonusTags(name: link.0 )  {
                moretags.insert(bonustag)
            }
        }
        if links.count == 0 { print("[crawler] no links for \(s) - check your music tree") } else {
            // print("createMdFile \(s)  bonustags:\(Array(moretags))")
            
            
            let stuff = renderMarkdown(s,tags:Array(moretags) + tags ,links:links)
            
            let markdownData: Data? = stuff.data(using: .utf8)
            // create md file with temp
            do {
                let mdseqnum = Int(Date().timeIntervalSinceReferenceDate*1000)
                let spec = "\(crawlerMarkDownOutputPath)/session\(String(format:"%011d",mdseqnum)).md"
                try markdownData!.write(to:URL(fileURLWithPath:  spec,isDirectory: false))
                
            } catch {
                print("Cant write file \(error)")
            }
        }
    }
    
    /// make some tags from the alburm name
    
    if  let u = URL(string:aurl){
        // take only the top two parts and use them as
        let parts = u.path.components(separatedBy: "/")
        var tags:[String]=[parts[1],parts[2]]
        // lets analyze parts3, if it is multispaced then lets call it a gig
        let subparts3 = parts[3].components(separatedBy: " ")
        var performanceKind = ""
        if (subparts3.count > 1) {
            performanceKind = "live"
            tags.append(subparts3[1])
        }
        else  {
            performanceKind = "rehearsal"
        }
        tags.append( performanceKind )
        let banner = parts[2] + " \(performanceKind) " + parts[3]
        
        // we actually dont care for the filename, it is autogenerated
        createMdFile(banner,tags:tags)
    }
    else{
        // print("cant \(String(describing: cont.albumurl))")
    }
}

private final class  CrawlingElement:Codable {
    
    //these are the only elements moved into the output stream
    
    var name:String? = ""
    var artist:String? = ""
    var albumurl:String? = ""
    var songurl:String = ""
    var cover_art_url:String? = ""
    var album : String?  {
        if let alurl = albumurl {
            let blurl = alurl.hasSuffix("/") ? String( alurl.dropLast()  ) : alurl
            if  let aname = blurl.components(separatedBy: "/").last {
                return aname
            }
        }
        return albumurl
    }
    
}


final class Transformer:NSObject,CustomControllable{
    
    var runman : CustomRunnable!
    var recordExporter : SingleRecordExporter!
    fileprivate var cont = CrawlingElement()
    var exportOptions:ExportMode!
    
    var firstTime = true
    var coverArtUrl : String?
    var artist : String
    
    func makeheader( ) -> String {
        return  "Name,Artist,Album,SongURL,AlbumURL,CoverArtURL"
    }
    func maketrailer( ) -> String?  {
        return    "==CrawlingContext=="
    }
    func makerow( ) -> String {
        func cleanItUp(_ r:CrawlingElement, kleenex:(String)->(String)) -> String {
            let z =
            """
            \(kleenex(r.name ?? "")),\(kleenex(r.artist ?? "")),\(kleenex(r.album ?? "")),\(kleenex(r.songurl)),\(kleenex(r.albumurl ?? "")),\(kleenex(r.cover_art_url ?? ""))
            """
            return z
        }
        return  cleanItUp(cont, kleenex:kleenex)
    }
    
    required  init(artist:String, defaultArtUrl:String? = nil, exportOptions:ExportMode = .csv ) {
        self.coverArtUrl = defaultArtUrl
        self.artist = artist
        self.exportOptions = exportOptions
        super.init()
        cleanOuputs(outpath: crawlerMarkDownOutputPath)
        
    }
    deinit  {
        recordExporter.addTrailerToExportStream()
    }
    
    func  incorporateParseResults(pr:ParseResults) {
        
        var mdlinks : [(String,String)] = []  // must reset each time !!
        // move the props into a record
        guard let url = pr.url else { fatalError() }
        // regardless of the type of export
        // var name:String = "no links!"
        
        
        for link in pr.links {
            let href =  link.href!.absoluteString
            if !href.hasSuffix("/" ) {
                cont.albumurl = url.absoluteString
                cont.name = link.title
                cont.songurl = href
                cont.artist = artist
                cont.cover_art_url = self.coverArtUrl
                mdlinks.append((cont.name ?? "??",cont.songurl))
                recordExporter.addRowToExportStream()
            }
        }
        
        // if we are writing md files for Publish
        if let aurl = cont.albumurl,
            exportOptions == .md {
            createMarkDown(aurl, name: cont.name?.lowercased(), links:mdlinks)
        }//writemdfiles==true
    }//incorporateParseResults
    
    
    func scraper(_ parseTechnique:ParseTechnique, url theURL:URL,
                 baseURL:URL?, html: String)   -> ParseResults? {
        
        var title: String = ""
        var links : [LinkElement] = []
        
        guard theURL.absoluteString.hasPrefix(baseURL!.absoluteString) else
        {
            return nil
        }
        // starts here
        if firstTime {
            recordExporter.addHeaderToExportStream()
            firstTime = false
        }
        
        
        do {
            assert(html.count != 0 , "No html to parse")
            let doc = try  HTML(html: html, encoding: .utf8)
            title = doc.title ?? "<untitled>"
            
            switch parseTechnique {
                
            case .parseTop,.parseLeaf:
                for link in doc.xpath("//a") { //[contains(@class, 'media-object')]
                    
                    absorbLink(link,relativeTo:theURL, tag: "media",links:&links )
                }
                
            case .indexDir:
                fatalError("forcedFailure induced")
                break;
            case .passThru:
                fatalError("forcedFailure induced")
            }
        }
        catch {
            print("cant parse error is \(error)")
            return  ParseResults(url: theURL, baseurl:baseURL, technique: parseTechnique,
                                 status: .failed(code: 0), pagetitle:title,
                                 links: links, props: [], tags: [])
        }
        
        return  ParseResults(url: theURL, baseurl:baseURL, technique: parseTechnique,
                             status: .succeeded, pagetitle: title,
                             links: links, props:[], tags: [])
    }
}

final public class KrawlMaster: CrawlMeister
{
    private var whenDone:ReturnsCrawlResults?
    
    public  func boot(name:String, baseURL:URL,configURL: URL, opath:String,logLevel:LoggingLevel,exportMode:ExportMode, finally:@escaping ReturnsCrawlResults) throws{
        self.whenDone = finally
        let fp = URL(string:opath)?.deletingPathExtension().absoluteString
        guard var fixedPath = fp else {fatalError("cant fix outpath")}
        switch exportMode {
        case .csv : fixedPath+=".csv"
        case .json : fixedPath+=".json"
        case .md : fixedPath+=".md"
        }
        
        
        let rm = RunnableStream(config:ConfigurationProcessor(baseURL),
                                custom: Transformer(artist: name,
                                                    defaultArtUrl: "booly",
                                                    exportOptions: exportMode),
                                outputFilePath: LocalFilePath(fixedPath),
                                outputType: exportMode,
                                runOptions: logLevel )
        
        let _ = try  CrawlingBeast( runman: rm,baseURL: baseURL,  configURL: configURL,options:logLevel,xoptions:exportMode,whenDone:finally)
    }
}
// this is where main calls in
private final class CrawlingBeast { 
    
    public init(
        // context:Crowdable,
        runman:CustomRunnable,
        baseURL: URL ,
        configURL: URL ,
        options:LoggingLevel = .none,
        xoptions:ExportMode = .json,
        whenDone:@escaping ReturnsCrawlResults) throws {
        
        let xpr = SingleRecordExporter(outputStream: outputStream, exportMode:xoptions, runman: runman)
        runman.custom.setupController(runman: runman, //context: context,
            exporter: xpr)
        runman.custom.startCrawling(baseURL:baseURL, configURL:configURL,loggingLevel: options,finally:whenDone )
        
    }
    
    enum Error: Swift.Error {
        case missingFileName
        case failedToCreateFile
        case badFilePath
    }
}
//MARK: - pass thru the music and art files, only
extension Transformer {
    func absorbLink(_ link: Kanna.XMLElement , relativeTo: URL?, tag: String, links: inout [LinkElement]) {
        if let lk = link["href"] ,
            let url = URL(string:lk,relativeTo:relativeTo) {
            let pextension = url.pathExtension.lowercased()
            let hasextension = pextension.count > 0
            let linktype:Linktype = hasextension == false ? .hyperlink:.leaf
            let txt = link.text ?? "-notext-"
            guard url.absoluteString.hasPrefix(relativeTo!.absoluteString) else {
                return
            }
            
            if hasextension {
                guard pextension == "mp3" || pextension == "wav" || pextension == "jpg" || pextension == "jpeg" || pextension == "png" else {
                    return
                    
                }
            } else
            {
                //  print("no ext: ", url)
            }
            
            // strip exension if any off the title
            let parts = txt.components(separatedBy: ".")
            if let ext  = parts.last,  let front = parts.first , ext.count > 0
            {
                let subparts = front.components(separatedBy: "-")
                if let titl = subparts.last {
                    let titw =  titl.trimmingCharacters(in: .whitespacesAndNewlines)
                    links.append(LinkElement(title:titw,href:url.absoluteString,linktype:linktype, relativeTo: relativeTo))
                }
                
            } else {
                // this is what happens upstream
                links.append(LinkElement(title:txt,href:url.absoluteString,linktype:linktype, relativeTo: relativeTo))
                
            }
        }
    }// end of absorbLink
}
